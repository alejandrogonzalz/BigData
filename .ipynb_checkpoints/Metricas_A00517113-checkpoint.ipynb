{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FsZKKvxwYF3o"
   },
   "source": [
    "# Actividad 4 | Métricas de calidad de resultados\n",
    "Identificar métricas para la medición de la calidad de resultados derivados de la aplicación de modelos de aprendizaje, ya sea supervisado o no supervisado, orientado al procesamiento de grandes volúmenes de datos, que permitan la selección de los modelos que mejor se ajusten a la tarea de aprendizaje a resolver.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UjmB97B-X-hU"
   },
   "source": "## Informacion del Equipo o Persona"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fYJBth0rYC0V"
   },
   "source": "Alejandro González Almazán - A00517113"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B0n2G2l_Yaze"
   },
   "source": "--------------------------------------------------------------------------------"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ar8PqEFjYfVA"
   },
   "source": "# Impotacion de Librerias"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "rFrmYAiPYdd9",
    "ExecuteTime": {
     "end_time": "2025-06-08T23:11:14.350621Z",
     "start_time": "2025-06-08T23:11:13.992397Z"
    }
   },
   "source": [
    "# PySpark\n",
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()\n",
    "from pyspark.sql import SparkSession\n",
    "\"\"\"\n",
    "# omitir para ejecutar de forma local\n",
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.1-bin-hadoop3.2\"\n",
    "\"\"\"\n",
    "#Librerias de codigo\n",
    "import kagglehub\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WXLHPUosZE5_"
   },
   "source": "### Inicializar entorno PySpark"
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "id": "GCAP0o7kcogx",
    "outputId": "1ed9ae58-97d4-422d-b102-c39be4f404db",
    "ExecuteTime": {
     "end_time": "2025-06-08T23:11:18.780504Z",
     "start_time": "2025-06-08T23:11:15.506Z"
    }
   },
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName(\"Analisis_Steam\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.conf.set(\"spark.sql.repl.eagerEval.enabled\", True)\n",
    "\n",
    "spark"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1fcb01d3170>"
      ],
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://Alex:4042\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.5</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Analisis_Steam</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zm2nuBbCZct4"
   },
   "source": "### Lectura de datos"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "nTiLMXpKZ3z9",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "750a6611-b09f-4fb9-91a3-edf92c244175",
    "ExecuteTime": {
     "end_time": "2025-06-08T23:11:26.865394Z",
     "start_time": "2025-06-08T23:11:26.631942Z"
    }
   },
   "source": "file_path = kagglehub.dataset_download(\"najzeko/steam-reviews-2021\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.12)\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T23:11:28.170211Z",
     "start_time": "2025-06-08T23:11:28.166685Z"
    }
   },
   "cell_type": "code",
   "source": "print(file_path)",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexa\\.cache\\kagglehub\\datasets\\najzeko\\steam-reviews-2021\\versions\\1\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "xlaqOdpzrRV5",
    "ExecuteTime": {
     "end_time": "2025-06-08T23:11:30.684084Z",
     "start_time": "2025-06-08T23:11:30.679932Z"
    }
   },
   "source": "print(f\"{file_path}/steam_reviews.csv\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexa\\.cache\\kagglehub\\datasets\\najzeko\\steam-reviews-2021\\versions\\1/steam_reviews.csv\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "BGv7gw7jZdgb",
    "ExecuteTime": {
     "end_time": "2025-06-08T23:18:37.916672Z",
     "start_time": "2025-06-08T23:17:55.609726Z"
    }
   },
   "source": [
    "df = spark.read.option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .option(\"multiLine\", \"true\") \\\n",
    "    .option(\"sep\", \",\").option(\"escape\", \"\\\"\").csv(f\"{file_path}/steam_reviews.csv\")\n",
    "\n",
    "new_columns = [col_name.replace(\".\", \"_\") for col_name in df.columns]\n",
    "df = df.toDF(*new_columns)"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F36rcs_erRWC"
   },
   "source": [
    "### 1. Construcción de la muestra M (Particiones Mi) con PySpark\n",
    "Para construir una muestra M representativa de la población P (dataset de reseñas de Steam), se generarán particiones Mi basadas en variables de caracterización clave. El objetivo es asegurar que cada Mi mantenga proporcionalidad respecto a la distribución original, evitando sesgos.\n",
    "\n",
    "#### Variables de Particionamiento\n",
    "Se utilizaron las siguientes variables categóricas identificadas en el análisis previo:\n",
    "\n",
    "1. **recommended:** Si el usuario recomienda el juego (True/False).\n",
    "\n",
    "2. **received_for_free:** Si el juego fue recibido gratis (True/False).\n",
    "\n",
    "3. **language:** Idioma de la reseña (ej. english, spanish, russian).\n",
    "\n",
    "#### Combinaciones relevantes:\n",
    "Estas variables generan 12 particiones únicas (ej: `reseñas en español`,` no recomendadas`, `recibidas gratis`).\n",
    "\n",
    "### Muestreo Estratificado Proporcional\n",
    "Para evitar sesgos:\n",
    "1. **Particiones (Mi)**: Se generaron combinando `language`, `received_for_free` y `recommended`.\n",
    "2. **Proporciones**: Cada Mi conserva su frecuencia original en el dataset (ej: inglés + gratis + recomendado = 14.2% → 14.2% en M).\n",
    "3. **Mínimo tamaño**: Particiones con <1,500 registros se incluyen completas."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Cálculo de Fracciones de Muestreo por Estrato\n",
    "\n",
    "Para construir una muestra `M` representativa y de tamaño controlado (`TAMAÑO_M`):\n",
    "\n",
    "1. **Fracción por estrato**:\n",
    "   - Se calcula como `(TAMAÑO_M * proporción_original) / conteo_original`.\n",
    "   - Esto asegura que cada estrato contribuya a `M` en proporción a su peso en el dataset original.\n",
    "\n",
    "2. **Límite del 100%**:\n",
    "   - Si un estrato es demasiado pequeño para contribuir al tamaño deseado sin superar el 100%, se incluye completo.\n",
    "\n",
    "3. **Diccionario de estratos**:\n",
    "   - Clave: Tupla `(language, received_for_free, recommended)`.\n",
    "   - Valor: Fracción de muestreo (ej: `0.3` para tomar el 30% del estrato)."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T23:38:20.363015Z",
     "start_time": "2025-06-08T23:36:03.407719Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Calcular conteos y proporciones originales\n",
    "conteos_originales = df.groupBy(\"language\", \"received_for_free\", \"recommended\") \\\n",
    "    .count() \\\n",
    "    .withColumn(\"proportion\", col(\"count\") / df.count())\n",
    "\n",
    "# Mostrar estratos y sus proporciones\n",
    "conteos_originales.orderBy(\"proportion\", ascending=False).show()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------------+-----------+-------+--------------------+\n",
      "| language|received_for_free|recommended|  count|          proportion|\n",
      "+---------+-----------------+-----------+-------+--------------------+\n",
      "|  english|            false|       true|8335990| 0.38331024012051845|\n",
      "| schinese|            false|       true|2832942|  0.1302659526064093|\n",
      "|  russian|            false|       true|1998749| 0.09190761494803211|\n",
      "|  english|            false|      false|1020063| 0.04690511786459154|\n",
      "| schinese|            false|      false| 844851|0.038848419884867924|\n",
      "|brazilian|            false|       true| 756037|   0.034764523950964|\n",
      "|  spanish|            false|       true| 728861| 0.03351490164029482|\n",
      "|   german|            false|       true| 650176|0.029896763153578424|\n",
      "|  turkish|            false|       true| 552688|0.025414014411213198|\n",
      "|  koreana|            false|       true| 502263| 0.02309534334058126|\n",
      "|   french|            false|       true| 477191|0.021942468356290056|\n",
      "|   polish|            false|       true| 449117| 0.02065155369814586|\n",
      "|  english|             true|       true| 248454| 0.01142455334026352|\n",
      "|  russian|            false|      false| 242361|0.011144381543865692|\n",
      "| tchinese|            false|       true| 177078|0.008142501454543632|\n",
      "|    czech|            false|       true| 119043|0.005473903029474229|\n",
      "|  italian|            false|       true| 116726|0.005367361415777567|\n",
      "|     thai|            false|       true| 108000|0.004966117513698552|\n",
      "|  russian|             true|       true|  96685|0.004445824738999487|\n",
      "|  koreana|            false|      false|  94422|0.004341766184059673|\n",
      "+---------+-----------------+-----------+-------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Calcular los estratos"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# 2. Definir tamaño deseado para M (ej: 2M registros)\n",
    "TAMAÑO_M = 2_000_000\n",
    "\n",
    "# 3. Calcular fracción de muestreo para cada estrato (evitando RDDs)\n",
    "estratos_df = conteos_originales.withColumn(\n",
    "    \"fraccion\",\n",
    "    (TAMAÑO_M * col(\"proportion\")) / col(\"count\")\n",
    ").withColumn(\n",
    "    \"fraccion\",\n",
    "    col(\"fraccion\").cast(\"double\")  # Asegurar tipo numérico\n",
    ")\n",
    "\n",
    "# 4. Limitar fracciones a 1.0 (100%)\n",
    "estratos_df = estratos_df.withColumn(\n",
    "    \"fraccion\",\n",
    "    when(col(\"fraccion\") > 1.0, 1.0).otherwise(col(\"fraccion\"))\n",
    ")\n",
    "\n",
    "# 5. Convertir a diccionario (opcional, si necesitas las fracciones en Python)\n",
    "estratos = {\n",
    "    (row[\"language\"], row[\"received_for_free\"], row[\"recommended\"]): row[\"fraccion\"]\n",
    "    for row in estratos_df.collect()\n",
    "}\n",
    "\n",
    "# Mostrar fracciones calculadas\n",
    "estratos_df.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# --------------------------\n",
    "# 1. Construcción de M (muestra estratificada)\n",
    "# --------------------------\n",
    "# Generar M\n",
    "muestras = [\n",
    "    df.filter(\n",
    "        (col(\"language\") == l) &\n",
    "        (col(\"received_for_free\") == f) &\n",
    "        (col(\"recommended\") == r)\n",
    "    ).sample(fraction=fr, seed=42)\n",
    "    for (l, f, r), fr in estratos.items()\n",
    "]\n",
    "\n",
    "M = spark.createDataFrame(spark.sparkContext.emptyRDD(), df.schema).unionByName(*muestras)\n",
    "\n",
    "# Validar proporciones en M\n",
    "print(\"Proporciones en M:\")\n",
    "M.groupBy(\"language\", \"received_for_free\", \"recommended\") \\\n",
    "    .count() \\\n",
    "    .withColumn(\"proportion\", col(\"count\") / M.count()) \\\n",
    "    .orderBy(\"proportion\", ascending=False) \\\n",
    "    .show()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Verificar proporciones en M vs P\n",
    "print(\"Distribución en P (original):\")\n",
    "df.groupBy(\"recommended\").count().show()\n",
    "\n",
    "print(\"Distribución en M (muestra estratificada):\")\n",
    "M.groupBy(\"recommended\").count().show()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "x = 5"
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
